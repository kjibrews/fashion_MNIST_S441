{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 441 Data Challenge 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a classification model based on the training set and use that model to\n",
    "make predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kristi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import packages and pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "#seed for reproducibility\n",
    "seed = 1234567\n",
    "np.random.seed(seed)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Convolution2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785) (10000, 785)\n"
     ]
    }
   ],
   "source": [
    "#import training and testing data\n",
    "#Each row in the train and test sets represent a 28 by 28 image.\n",
    "train_data = pd.read_csv(\"C:/Users\\Kristi/Documents/Fall 2018/STAT 441/DataChallenge 1/fashion-mnist_train.csv\").values\n",
    "test_data = pd.read_csv(\"C:/Users\\Kristi/Documents/Fall 2018/STAT 441/DataChallenge 1/test_data.csv\").values\n",
    "\n",
    "print(train_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "# Define the text labels 0-9\n",
    "fashion_mnist_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\", \"Dress\",\"Coat\",\n",
    "                        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (10000,)\n"
     ]
    }
   ],
   "source": [
    "#split into input and output\n",
    "Y_train = train_data[:,0] #labels\n",
    "Y_test = test_data[:,0] #ids\n",
    "print(Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "Y_train = lb.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#reshape and normalise data into images so keras can be used\n",
    "X_train = train_data[:,1:] #pixels\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype(\"float32\")\n",
    "X_train = np.true_divide(X_train, 255)\n",
    "\n",
    "X_test = test_data[:,1:] #pixels\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype(\"float32\")\n",
    "X_test = np.true_divide(X_test, 255)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "#Model has 10 labels \n",
    "\n",
    "model = Sequential() #initialise nn\n",
    "#\n",
    "model.add(Convolution2D(64,kernel_size = (2,2),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "#model.add(Dropout(0.2)) #avoid overfiltering\n",
    "#\n",
    "model.add(Convolution2D(64,kernel_size = (2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.2)) #avoid overfiltering\n",
    " \n",
    "#Full connection\n",
    "model.add(Flatten()) #flatten to 1d\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.4))#avoid overfiltering\n",
    "model.add(Dense(10, activation='softmax')) #initialise output layer\n",
    "#Compile CNN\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 27, 27, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 12, 12, 64)        16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1024)              2360320   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,387,338\n",
      "Trainable params: 2,387,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 358s 6ms/step - loss: 0.4623 - acc: 0.8310\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 356s 6ms/step - loss: 0.3076 - acc: 0.8867\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 361s 6ms/step - loss: 0.2645 - acc: 0.9020\n",
      "Epoch 4/10\n",
      "26880/60000 [============>.................] - ETA: 1:38:21 - loss: 0.2321 - acc: 0.9138"
     ]
    }
   ],
   "source": [
    "#Train network\n",
    "ephs = 10\n",
    "batchze = 64\n",
    "model.fit(X_train, Y_train, batch_size = batchze, epochs = ephs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 1 ... 4 8 1]\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "#make predictions for the test set\n",
    "label_pred = model.predict(X_test)\n",
    "label_pred = np.argmax(label_pred, axis = 1)\n",
    "print(label_pred)\n",
    "print(label_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sumbmission results to a csv \n",
    "submission = {'ids':Y_test, 'label':label_pred}\n",
    "submission = pd.DataFrame(submission)\n",
    "submission.head()\n",
    "submission.to_csv(\"C:/Users/Kristi/Documents/Fall 2018/STAT 441/DataChallenge 1/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9303\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(xtest, ytest, verbose=0)\n",
    "print('Test accuracy:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\n",
    "    \"C:/Users\\Kristi/Documents/Fall 2018/STAT 441/DataChallenge 1/kaggle_fashion-mnist_train.csv\").values\n",
    "testing = pd.read_csv(\n",
    "    \"C:/Users\\Kristi/Documents/Fall 2018/STAT 441/DataChallenge 1/fashion-mnist_test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
      "60000 train set\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-bb92e4a27e1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Print the number of training and test datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Define the text labels 0-9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xtest' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ytrain = training[:,0] #labels\n",
    "xtrain = training[:,1:] #pixels\n",
    "xtrain = xtrain.reshape(xtrain.shape[0],28,28).astype(\"float32\")\n",
    "\n",
    "# Print training set shape - note there are 60,000 training data of image size of 28x28, 60,000 train labels)\n",
    "print(\"x_train shape:\", xtrain.shape, \"y_train shape:\", ytrain.shape)\n",
    "\n",
    "# Print the number of training and test datasets\n",
    "print(xtrain.shape[0], 'train set')\n",
    "print(xtest.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels 0-9\n",
    "fashion_mnist_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\", \"Dress\",\"Coat\",\n",
    "                        \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]   \n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = ytrain[img_index]\n",
    "# Print the label, for example 2 Pullover\n",
    "print(\"y = \" + str(label_index) + \" \" + str(fashion_mnist_labels[label_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10)\n",
      "(10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "ytest = testing[:,0] #labels\n",
    "ytest = lb.fit_transform(ytest)\n",
    "ytrain = training[:,0] #labels\n",
    "ytrain = lb.fit_transform(ytrain)\n",
    "\n",
    "xtest = testing[:,1:] #pixels\n",
    "xtest = xtest.reshape(xtest.shape[0],28,28,1).astype(\"float32\")\n",
    "xtest = np.true_divide(xtest, 255)\n",
    "xtrain = training[:,1:] #pixels\n",
    "xtrain = xtrain.reshape(xtrain.shape[0],28,28,1).astype(\"float32\")\n",
    "xtrain = np.true_divide(xtrain, 255)\n",
    "print(xtrain.shape, ytrain.shape)\n",
    "print(xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model\n",
    "#Model has 10 labels \n",
    "\n",
    "model = Sequential() #initialise nn\n",
    "#\n",
    "model.add(Convolution2D(64,kernel_size = (2,2),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) \n",
    "model.add(Dropout(0.2)) #avoid overfiltering\n",
    "#\n",
    "model.add(Convolution2D(64,kernel_size = (2,2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2)) #avoid overfiltering\n",
    " \n",
    "#Full connection\n",
    "model.add(Flatten()) #flatten to 1d\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))#avoid overfiltering\n",
    "model.add(Dense(10, activation='softmax')) #initialise output layer\n",
    "#Compile CNN\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 2  \n",
    "model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs,verbose=1, \n",
    "          validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2  \n",
    "model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs,verbose=1, \n",
    "          validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2  \n",
    "model.fit(xtrain, ytrain, batch_size=batch_size, epochs=epochs,verbose=1, \n",
    "          validation_data=(xtest, ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(xtest, ytest, verbose=0)\n",
    "print('Test accuracy:',score[1])\n",
    "\n",
    "#View prediction\n",
    "y_hat = model.predict(xtest)\n",
    "label_predict = np.argmax(y_hat, axis = 1)\n",
    "print(label_predict)\n",
    "print(label_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(0, 10000, 1)\n",
    "submission = {'ids':a, 'label':label_predict}\n",
    "submission = pd.DataFrame(submission)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a random sample of 20 test images, their predicted labels and ground truth\n",
    "for i, index in enumerate(np.random.choice(xtest.shape[0], size=20, replace=False)):\n",
    "    # Display each image\n",
    "    predict_index = np.argmax(y_hat[index])\n",
    "    true_index = np.argmax(ytest[index])\n",
    "    # Set the title for each image\n",
    "    print(\"Predict: \" + str(fashion_mnist_labels[predict_index]), \"    \",\n",
    "          \"True: \" + str(fashion_mnist_labels[true_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
